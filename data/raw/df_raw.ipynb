{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a089846",
   "metadata": {},
   "source": [
    "EDA — Credit Card Clients (Default / Late Payment Risk) by Kasia Mc art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461faf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# -----------------------------------------------------------------------------\n",
    "DATA_PATH = Path(\"default of credit card clients.xls\")  # keep file next to this notebook, or update path\n",
    "SHEET_NAME = 0\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"Data path:\", DATA_PATH.resolve() if DATA_PATH.exists() else DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73435007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# HELPERS (same style as stock EDA notebook)\n",
    "# -----------------------------------------------------------------------------\n",
    "def print_df(df: pd.DataFrame, name: str, n: int = 10):\n",
    "    print(\"\\n\" + \"-\" * 95)\n",
    "    print(f\"[DATAFRAME] {name} | shape = {df.shape[0]:,} rows × {df.shape[1]:,} cols\")\n",
    "    print(\"-\" * 95)\n",
    "    print(df.head(n).to_string())\n",
    "\n",
    "def section(title: str):\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(title)\n",
    "    print(\"=\" * 95)\n",
    "\n",
    "def pct(x):\n",
    "    return 100 * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61302537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA\n",
    "# =============================================================================\n",
    "section(\"Loading data\")\n",
    "\n",
    "# NOTE: this dataset is often in legacy .xls format; pandas may require xlrd.\n",
    "# If you get an error like \"Missing optional dependency 'xlrd'\", run:\n",
    "#   pip install xlrd==2.0.1\n",
    "\n",
    "df_raw = pd.read_excel(DATA_PATH, sheet_name=SHEET_NAME, header=1, engine=\"xlrd\")\n",
    "\n",
    "print_df(df_raw, \"raw\")\n",
    "df_raw.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3405e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLEAN COLUMN NAMES\n",
    "# =============================================================================\n",
    "section(\"Cleaning column names\")\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Standardize target name\n",
    "df = df.rename(columns={\"default payment next month\": \"DEFAULT_NEXT_MONTH\"})\n",
    "\n",
    "# Ensure ID exists\n",
    "if \"ID\" in df.columns:\n",
    "    df[\"ID\"] = df[\"ID\"].astype(int)\n",
    "\n",
    "print_df(df, \"cleaned\")\n",
    "print(\"Target distribution (counts):\")\n",
    "print(df[\"DEFAULT_NEXT_MONTH\"].value_counts(dropna=False).to_string())\n",
    "print(\"\\nTarget distribution (rate %):\")\n",
    "print((df[\"DEFAULT_NEXT_MONTH\"].value_counts(normalize=True) * 100).round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02718e3",
   "metadata": {},
   "source": [
    "## Data dictionary (high level)\n",
    "\n",
    "**Target**\n",
    "- `DEFAULT_NEXT_MONTH` — 1 = default next month, 0 = not default\n",
    "\n",
    "**Static customer profile**\n",
    "- `LIMIT_BAL` — credit limit\n",
    "- `SEX`, `EDUCATION`, `MARRIAGE`, `AGE`\n",
    "\n",
    "**Repayment status (behaviour)**\n",
    "- `PAY_0`, `PAY_2`, `PAY_3`, `PAY_4`, `PAY_5`, `PAY_6`  \n",
    "  (repayment status for the last 6 months; higher values = more delayed)\n",
    "\n",
    "**Billing history**\n",
    "- `BILL_AMT1` … `BILL_AMT6` — monthly statement balances\n",
    "\n",
    "**Payment history**\n",
    "- `PAY_AMT1` … `PAY_AMT6` — monthly payments made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA QUALITY CHECKS\n",
    "# =============================================================================\n",
    "section(\"Data quality checks\")\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "na = df.isna().sum().sort_values(ascending=False)\n",
    "print(na[na>0].to_string() if (na>0).any() else \"No missing values found.\")\n",
    "\n",
    "# Duplicate ID check (if ID column exists)\n",
    "if \"ID\" in df.columns:\n",
    "    dup = df[\"ID\"].duplicated().sum()\n",
    "    print(f\"Duplicate IDs: {dup}\")\n",
    "\n",
    "# Basic describe\n",
    "section(\"describe() — numeric\")\n",
    "print(df.describe().T.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATEGORICAL VARIABLES — DISTRIBUTIONS\n",
    "# =============================================================================\n",
    "section(\"Categorical variables distributions\")\n",
    "\n",
    "cat_cols = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "for c in cat_cols:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"{c} value_counts:\")\n",
    "    print(df[c].value_counts(dropna=False).to_string())\n",
    "    fig = px.bar(\n",
    "        df[c].value_counts().reset_index(),\n",
    "        x=\"index\", y=c,\n",
    "        title=f\"{c} distribution\",\n",
    "        labels={\"index\": c, c: \"count\"}\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NUMERIC VARIABLES — DISTRIBUTIONS\n",
    "# =============================================================================\n",
    "section(\"Numeric variables distributions\")\n",
    "\n",
    "num_cols = [\"LIMIT_BAL\", \"AGE\"]\n",
    "for c in num_cols:\n",
    "    fig = px.histogram(df, x=c, nbins=50, title=f\"{c} — histogram\")\n",
    "    fig.show()\n",
    "\n",
    "# Boxplots for quick outlier scan\n",
    "fig = px.box(df, y=\"LIMIT_BAL\", title=\"LIMIT_BAL — boxplot\")\n",
    "fig.show()\n",
    "fig = px.box(df, y=\"AGE\", title=\"AGE — boxplot\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae213317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TARGET vs FEATURES (quick comparisons)\n",
    "# =============================================================================\n",
    "section(\"Target rate by categories\")\n",
    "\n",
    "for c in [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]:\n",
    "    g = (df.groupby(c)[\"DEFAULT_NEXT_MONTH\"]\n",
    "           .agg([\"count\",\"mean\"])\n",
    "           .rename(columns={\"mean\":\"default_rate\"}))\n",
    "    g[\"default_rate_pct\"] = (g[\"default_rate\"]*100).round(2)\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"DEFAULT rate by {c}:\")\n",
    "    print(g.sort_values(\"default_rate\", ascending=False).to_string())\n",
    "\n",
    "    fig = px.bar(g.reset_index(), x=c, y=\"default_rate_pct\",\n",
    "                 title=f\"Default rate (%) by {c}\",\n",
    "                 labels={\"default_rate_pct\":\"default rate (%)\"})\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# REPAYMENT STATUS (PAY_*) — KEY RISK SIGNALS\n",
    "# =============================================================================\n",
    "section(\"Repayment status (PAY_*) overview\")\n",
    "\n",
    "pay_cols = [\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\"]\n",
    "for c in pay_cols:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"{c} value_counts (top):\")\n",
    "    print(df[c].value_counts().head(12).to_string())\n",
    "\n",
    "# Default rate by each PAY_* status (example: PAY_0)\n",
    "section(\"Default rate by PAY_0\")\n",
    "g = (df.groupby(\"PAY_0\")[\"DEFAULT_NEXT_MONTH\"]\n",
    "       .agg([\"count\",\"mean\"])\n",
    "       .rename(columns={\"mean\":\"default_rate\"}))\n",
    "g[\"default_rate_pct\"] = (g[\"default_rate\"]*100).round(2)\n",
    "print(g.sort_values(\"default_rate\", ascending=False).to_string())\n",
    "\n",
    "fig = px.bar(g.reset_index(), x=\"PAY_0\", y=\"default_rate_pct\",\n",
    "             title=\"Default rate (%) by PAY_0\",\n",
    "             labels={\"default_rate_pct\":\"default rate (%)\"})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceece0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BILLING + PAYMENTS — MONTHLY PATTERNS (mean / median)\n",
    "# =============================================================================\n",
    "section(\"Billing and payments — monthly patterns\")\n",
    "\n",
    "bill_cols = [f\"BILL_AMT{i}\" for i in range(1,7)]\n",
    "pay_amt_cols = [f\"PAY_AMT{i}\" for i in range(1,7)]\n",
    "\n",
    "bill_stats = df[bill_cols].agg([\"mean\",\"median\"]).T\n",
    "pay_stats  = df[pay_amt_cols].agg([\"mean\",\"median\"]).T\n",
    "\n",
    "print(\"\\nBilling stats (mean/median):\")\n",
    "print(bill_stats.to_string())\n",
    "print(\"\\nPayment stats (mean/median):\")\n",
    "print(pay_stats.to_string())\n",
    "\n",
    "# Line charts\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=bill_stats.index, y=bill_stats[\"mean\"], mode=\"lines+markers\", name=\"Bill mean\"))\n",
    "fig.add_trace(go.Scatter(x=bill_stats.index, y=bill_stats[\"median\"], mode=\"lines+markers\", name=\"Bill median\"))\n",
    "fig.update_layout(title=\"Billing amounts over last 6 months (mean vs median)\", xaxis_title=\"month column\", yaxis_title=\"amount\")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=pay_stats.index, y=pay_stats[\"mean\"], mode=\"lines+markers\", name=\"Pay mean\"))\n",
    "fig.add_trace(go.Scatter(x=pay_stats.index, y=pay_stats[\"median\"], mode=\"lines+markers\", name=\"Pay median\"))\n",
    "fig.update_layout(title=\"Payment amounts over last 6 months (mean vs median)\", xaxis_title=\"month column\", yaxis_title=\"amount\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORRELATIONS (numeric)\n",
    "# =============================================================================\n",
    "section(\"Correlation heatmap (numeric)\")\n",
    "\n",
    "# Correlation can be dominated by outliers; consider also Spearman in addition to Pearson.\n",
    "num_for_corr = df.drop(columns=[\"ID\"], errors=\"ignore\").select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "corr_pearson = num_for_corr.corr(method=\"pearson\")\n",
    "corr_spearman = num_for_corr.corr(method=\"spearman\")\n",
    "\n",
    "fig = px.imshow(corr_pearson, title=\"Correlation heatmap (Pearson)\", aspect=\"auto\")\n",
    "fig.show()\n",
    "\n",
    "fig = px.imshow(corr_spearman, title=\"Correlation heatmap (Spearman)\", aspect=\"auto\")\n",
    "fig.show()\n",
    "\n",
    "# Quick top correlations with target\n",
    "section(\"Top absolute correlations with target (Pearson)\")\n",
    "target_corr = corr_pearson[\"DEFAULT_NEXT_MONTH\"].drop(\"DEFAULT_NEXT_MONTH\").abs().sort_values(ascending=False)\n",
    "print(target_corr.head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58295dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING (for ML)\n",
    "# =============================================================================\n",
    "section(\"Feature engineering\")\n",
    "\n",
    "df_fe = df.copy()\n",
    "\n",
    "# --- Clean up category codes (common practice for this dataset) ---\n",
    "# EDUCATION: 0, 5, 6 are often \"unknown\" -> group as 4 (Other)\n",
    "df_fe[\"EDUCATION\"] = df_fe[\"EDUCATION\"].replace({0: 4, 5: 4, 6: 4})\n",
    "# MARRIAGE: 0 often unknown -> group as 3 (Other)\n",
    "df_fe[\"MARRIAGE\"] = df_fe[\"MARRIAGE\"].replace({0: 3})\n",
    "\n",
    "# --- Payment ratio features ---\n",
    "bill_cols = [f\"BILL_AMT{i}\" for i in range(1,7)]\n",
    "pay_cols_amt = [f\"PAY_AMT{i}\" for i in range(1,7)]\n",
    "\n",
    "for i in range(1,7):\n",
    "    b = f\"BILL_AMT{i}\"\n",
    "    p = f\"PAY_AMT{i}\"\n",
    "    df_fe[f\"PAY_RATIO{i}\"] = df_fe[p] / (df_fe[b].abs() + 1)  # +1 to avoid division by zero\n",
    "\n",
    "# --- Utilization proxy ---\n",
    "df_fe[\"UTILIZATION6M_MEAN\"] = (df_fe[bill_cols].clip(lower=0).mean(axis=1)) / (df_fe[\"LIMIT_BAL\"] + 1)\n",
    "\n",
    "# --- Aggregates over 6 months ---\n",
    "df_fe[\"BILL_TOTAL_6M\"] = df_fe[bill_cols].sum(axis=1)\n",
    "df_fe[\"PAY_TOTAL_6M\"]  = df_fe[pay_cols_amt].sum(axis=1)\n",
    "df_fe[\"PAY_RATIO_6M_MEAN\"] = df_fe[[f\"PAY_RATIO{i}\" for i in range(1,7)]].mean(axis=1)\n",
    "\n",
    "# --- Delinquency features ---\n",
    "pay_status_cols = [\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\"]\n",
    "df_fe[\"MAX_DELAY_6M\"] = df_fe[pay_status_cols].max(axis=1)\n",
    "df_fe[\"MEAN_DELAY_6M\"] = df_fe[pay_status_cols].mean(axis=1)\n",
    "df_fe[\"MONTHS_LATE_6M\"] = (df_fe[pay_status_cols] > 0).sum(axis=1)\n",
    "df_fe[\"RECENT_DELAY\"] = df_fe[\"PAY_0\"]  # closest month\n",
    "\n",
    "# --- Trend features (simple slope) ---\n",
    "def slope_6(values):\n",
    "    x = np.arange(len(values))\n",
    "    try:\n",
    "        return np.polyfit(x, values, 1)[0]\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "df_fe[\"BILL_SLOPE_6M\"] = df_fe[bill_cols].apply(lambda r: slope_6(r.values), axis=1)\n",
    "df_fe[\"PAY_SLOPE_6M\"]  = df_fe[pay_cols_amt].apply(lambda r: slope_6(r.values), axis=1)\n",
    "\n",
    "print_df(df_fe, \"df_fe (engineered)\", n=5)\n",
    "\n",
    "# Sanity check: engineered columns summary\n",
    "section(\"Engineered features summary\")\n",
    "eng_cols = [c for c in df_fe.columns if \"RATIO\" in c or \"UTIL\" in c or \"TOTAL\" in c or \"SLOPE\" in c or \"DELAY\" in c or \"MONTHS_LATE\" in c]\n",
    "print(df_fe[eng_cols].describe().T.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODELING PREP (baseline) — optional but useful in an ML notebook\n",
    "# =============================================================================\n",
    "section(\"Modeling prep (baseline)\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "target = \"DEFAULT_NEXT_MONTH\"\n",
    "\n",
    "X = df_fe.drop(columns=[target], errors=\"ignore\")\n",
    "y = df_fe[target].astype(int)\n",
    "\n",
    "# Define feature types\n",
    "cat_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "num_features = [c for c in X.columns if c not in cat_features and c != \"ID\"]\n",
    "\n",
    "# Train/test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "        (\"num\", StandardScaler(with_mean=False), num_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Baseline 1: Logistic Regression (interpretable)\n",
    "lr = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "# Baseline 2: Random Forest (non-linear)\n",
    "rf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"LogReg (balanced)\": lr,\n",
    "    \"RandomForest\": rf\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    section(f\"Training: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict probabilities\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    ap  = average_precision_score(y_test, proba)\n",
    "    print(f\"ROC AUC: {auc:.4f}\")\n",
    "    print(f\"PR AUC : {ap:.4f}\")\n",
    "\n",
    "    # classification report at default threshold 0.5\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, pred, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9272bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED MODELS (optional) — Gradient Boosting / XGBoost / LightGBM / CatBoost\n",
    "# =============================================================================\n",
    "section(\"Advanced models (optional)\")\n",
    "\n",
    "# These are not always installed in every environment.\n",
    "# If installed, they often outperform baselines on this dataset.\n",
    "\n",
    "advanced_results = []\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    xgb = Pipeline(steps=[\n",
    "        (\"prep\", preprocess),\n",
    "        (\"model\", XGBClassifier(\n",
    "            n_estimators=600,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=1.0,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    section(\"Training: XGBoost\")\n",
    "    xgb.fit(X_train, y_train)\n",
    "    proba = xgb.predict_proba(X_test)[:, 1]\n",
    "    advanced_results.append((\"XGBoost\", roc_auc_score(y_test, proba), average_precision_score(y_test, proba)))\n",
    "except Exception as e:\n",
    "    print(\"XGBoost not available or failed to import/train:\", e)\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    lgbm = Pipeline(steps=[\n",
    "        (\"prep\", preprocess),\n",
    "        (\"model\", lgb.LGBMClassifier(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.03,\n",
    "            num_leaves=31,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    section(\"Training: LightGBM\")\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    proba = lgbm.predict_proba(X_test)[:, 1]\n",
    "    advanced_results.append((\"LightGBM\", roc_auc_score(y_test, proba), average_precision_score(y_test, proba)))\n",
    "except Exception as e:\n",
    "    print(\"LightGBM not available or failed to import/train:\", e)\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "    # CatBoost can handle categorical features natively, but we keep the same pipeline style for consistency.\n",
    "    cat = Pipeline(steps=[\n",
    "        (\"prep\", preprocess),\n",
    "        (\"model\", CatBoostClassifier(\n",
    "            iterations=1000,\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            loss_function=\"Logloss\",\n",
    "            verbose=False,\n",
    "            random_seed=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    section(\"Training: CatBoost\")\n",
    "    cat.fit(X_train, y_train)\n",
    "    proba = cat.predict_proba(X_test)[:, 1]\n",
    "    advanced_results.append((\"CatBoost\", roc_auc_score(y_test, proba), average_precision_score(y_test, proba)))\n",
    "except Exception as e:\n",
    "    print(\"CatBoost not available or failed to import/train:\", e)\n",
    "\n",
    "if advanced_results:\n",
    "    section(\"Advanced models summary\")\n",
    "    for name, auc, ap in sorted(advanced_results, key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{name:10s} | ROC AUC={auc:.4f} | PR AUC={ap:.4f}\")\n",
    "else:\n",
    "    print(\"No advanced model results available (libraries may not be installed).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
